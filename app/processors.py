import base64
import cv2
import numpy as np
from typing import List, Dict, Any
import logging
from io import BytesIO
from PIL import Image
from app.models import LandmarkPoint, ProcessResponse
import os

logger = logging.getLogger(__name__)

class FacialSVGProcessor:
    def __init__(self):
        self.region_styles = {
            1: {"fill": "rgba(255,0,0,0.3)", "stroke": "red", "stroke-dasharray": "5,5"},
            2: {"fill": "rgba(0,255,0,0.3)", "stroke": "green", "stroke-dasharray": "5,5"},
            3: {"fill": "rgba(0,0,255,0.3)", "stroke": "blue", "stroke-dasharray": "5,5"},
            4: {"fill": "rgba(255,255,0,0.3)", "stroke": "yellow", "stroke-dasharray": "5,5"},
        }
        self.load_testing_mode = os.getenv('LOAD_TESTING_MODE', 'false').lower() == 'true'

    def base64_to_image(self, base64_string: str) -> np.ndarray:
        """Convert base64 string to OpenCV image"""
        try:
            if ',' in base64_string:
                base64_string = base64_string.split(',')[1]

            image_data = base64.b64decode(base64_string)
            image = Image.open(BytesIO(image_data))
            return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        except Exception as e:
            logger.error(f"Error decoding base64 image: {e}")
            raise ValueError("Invalid image data")

    def estimate_rotation_angle(self, landmarks: List[LandmarkPoint]) -> float:
        """Estimate face rotation angle from landmarks"""
        try:
            points = np.array([[lm.x, lm.y] for lm in landmarks])

            # Use eye landmarks for rotation estimation
            left_eye_indices = [33, 133, 144, 145]
            right_eye_indices = [362, 263, 373, 374]

            # Calculate eye centers
            left_eye_center = np.mean([points[i] for i in left_eye_indices if i < len(points)], axis=0)
            right_eye_center = np.mean([points[i] for i in right_eye_indices if i < len(points)], axis=0)

            # Calculate angle
            dy = right_eye_center[1] - left_eye_center[1]
            dx = right_eye_center[0] - left_eye_center[0]
            angle = np.degrees(np.arctan2(dy, dx))

            logger.info(f"Estimated rotation angle: {angle:.2f} degrees")
            return angle

        except Exception as e:
            logger.warning(f"Could not estimate rotation angle: {e}")
            return 0.0

    def align_face(self, image: np.ndarray, landmarks: List[LandmarkPoint]) -> tuple:
        """Align face to upright position"""
        angle = self.estimate_rotation_angle(landmarks)

        if abs(angle) < 2:
            return image, landmarks

        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        aligned_image = cv2.warpAffine(image, rotation_matrix, (width, height), flags=cv2.INTER_CUBIC)

        aligned_landmarks = []
        for lm in landmarks:
            point = np.array([lm.x, lm.y, 1])
            rotated_point = rotation_matrix @ point
            aligned_landmarks.append(LandmarkPoint(x=rotated_point[0], y=rotated_point[1]))

        logger.info(f"Aligned face by {angle:.2f} degrees")
        return aligned_image, aligned_landmarks

    def create_smooth_path(self, points: List[LandmarkPoint]) -> str:
        """Create smooth SVG path from points"""
        if len(points) < 3:
            return ""

        coords = np.array([[p.x, p.y] for p in points])
        path_commands = [f"M {coords[0][0]:.2f} {coords[0][1]:.2f}"]

        for i in range(1, len(coords)):
            path_commands.append(f"L {coords[i][0]:.2f} {coords[i][1]:.2f}")

        path_commands.append("Z")
        return " ".join(path_commands)

    def generate_svg(self, contours: Dict[int, List[LandmarkPoint]], width: int, height: int) -> str:
        """Generate SVG with contour overlays"""
        svg_content = [
            f'<svg width="{width}" height="{height}" xmlns="http://www.w3.org/2000/svg">',
            '<!-- Generated by Facial SVG Service -->'
        ]

        for region_id, points in contours.items():
            if len(points) < 3:
                continue

            style = self.region_styles.get(region_id, self.region_styles[1])
            path_data = self.create_smooth_path(points)

            if path_data:
                svg_content.append(
                    f'<path d="{path_data}" '
                    f'fill="{style["fill"]}" '
                    f'stroke="{style["stroke"]}" '
                    f'stroke-width="2" '
                    f'stroke-dasharray="{style["stroke-dasharray"]}" '
                    f'fill-rule="evenodd"/>'
                )

        svg_content.append('</svg>')
        return "\n".join(svg_content)

    def process_segmentation_map(self, segmentation_base64: str, landmarks: List[LandmarkPoint]) -> Dict[int, List[LandmarkPoint]]:
        """Process segmentation map to extract region contours"""
        contours = {}

        if len(landmarks) > 50:
            # Create example regions - you'll need to implement actual segmentation
            if len(landmarks) > 100:
                contours[1] = landmarks[100:120]
            if len(landmarks) > 300:
                contours[2] = landmarks[300:320]
            if len(landmarks) > 10:
                contours[3] = landmarks[10:25]

        logger.info(f"Created {len(contours)} contour regions")
        return contours

    def process_request(self, request_data) -> ProcessResponse:
        """Main processing function"""
        try:
            # Simulate delay only if not in load testing mode
            if not self.load_testing_mode:
                import time
                time.sleep(2)  # Small delay for non-load testing

            original_image = self.base64_to_image(request_data.image)
            landmarks = self._parse_landmarks(request_data.landmarks)

            if len(landmarks) < 10:
                raise ValueError("Insufficient landmarks for face detection")

            aligned_image, aligned_landmarks = self.align_face(original_image, landmarks)
            contours = self.process_segmentation_map(request_data.segmentation_map, aligned_landmarks)

            height, width = aligned_image.shape[:2]
            svg_string = self.generate_svg(contours, width, height)
            svg_base64 = base64.b64encode(svg_string.encode('utf-8')).decode('utf-8')

            mask_contours = {}
            for region_id, points in contours.items():
                mask_contours[region_id] = [[p.x, p.y] for p in points]

            return ProcessResponse(
                svg=svg_base64,
                mask_contours=mask_contours
            )

        except Exception as e:
            logger.error(f"Error processing request: {e}")
            raise

    def _parse_landmarks(self, landmarks_data):
        """Handle different landmark data structures"""
        if not landmarks_data:
            return []

        if isinstance(landmarks_data[0], LandmarkPoint):
            return landmarks_data

        if isinstance(landmarks_data[0], dict) and 'x' in landmarks_data[0]:
            return [LandmarkPoint(x=point['x'], y=point['y']) for point in landmarks_data]

        if (isinstance(landmarks_data[0], list) and
                landmarks_data[0] and
                isinstance(landmarks_data[0][0], dict) and
                'x' in landmarks_data[0][0]):
            flattened = []
            for sublist in landmarks_data:
                for point in sublist:
                    flattened.append(LandmarkPoint(x=point['x'], y=point['y']))
            return flattened

        logger.warning(f"Unknown landmarks structure: {type(landmarks_data)}")
        return []
