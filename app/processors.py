import base64
import cv2
import numpy as np
from typing import List, Dict, Any
import logging
from io import BytesIO
from PIL import Image
from app.models import LandmarkPoint, ProcessResponse
import os

logger = logging.getLogger(__name__)


class FacialSVGProcessor:
    def __init__(self):
        self.region_styles = {
            1: {
                "fill": "rgba(255,0,0,0.3)",
                "stroke": "red",
                "stroke-dasharray": "5,5",
            },
            2: {
                "fill": "rgba(0,255,0,0.3)",
                "stroke": "green",
                "stroke-dasharray": "5,5",
            },
            3: {
                "fill": "rgba(0,0,255,0.3)",
                "stroke": "blue",
                "stroke-dasharray": "5,5",
            },
            4: {
                "fill": "rgba(255,255,0,0.3)",
                "stroke": "yellow",
                "stroke-dasharray": "5,5",
            },
        }
        self.load_testing_mode = (
            os.getenv("LOAD_TESTING_MODE", "false").lower() == "true"
        )

    def base64_to_image(self, base64_string: str) -> np.ndarray:
        """Convert base64 string to OpenCV image"""
        try:
            if "," in base64_string:
                base64_string = base64_string.split(",")[1]

            image_data = base64.b64decode(base64_string)
            image = Image.open(BytesIO(image_data))
            return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        except Exception as e:
            logger.error(f"Error decoding base64 image: {e}")
            raise ValueError("Invalid image data")

    def estimate_rotation_angle(self, landmarks: List[LandmarkPoint]) -> float:
        """Estimate face rotation angle from landmarks"""
        try:
            points = np.array([[lm.x, lm.y] for lm in landmarks])

            # Use eye landmarks for rotation estimation
            left_eye_indices = [33, 133, 144, 145]
            right_eye_indices = [362, 263, 373, 374]

            # Calculate eye centers
            left_eye_center = np.mean(
                [points[i] for i in left_eye_indices if i < len(points)], axis=0
            )
            right_eye_center = np.mean(
                [points[i] for i in right_eye_indices if i < len(points)], axis=0
            )

            # Calculate angle
            dy = right_eye_center[1] - left_eye_center[1]
            dx = right_eye_center[0] - left_eye_center[0]
            angle = np.degrees(np.arctan2(dy, dx))

            logger.info(f"Estimated rotation angle: {angle:.2f} degrees")
            return angle

        except Exception as e:
            logger.warning(f"Could not estimate rotation angle: {e}")
            return 0.0

    def align_face(self, image: np.ndarray, landmarks: List[LandmarkPoint]) -> tuple:
        """Align face to upright position"""
        angle = self.estimate_rotation_angle(landmarks)

        if abs(angle) < 2:
            return image, landmarks

        height, width = image.shape[:2]
        center = (width // 2, height // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
        aligned_image = cv2.warpAffine(
            image, rotation_matrix, (width, height), flags=cv2.INTER_CUBIC
        )

        aligned_landmarks = []
        for lm in landmarks:
            point = np.array([lm.x, lm.y, 1])
            rotated_point = rotation_matrix @ point
            aligned_landmarks.append(
                LandmarkPoint(x=rotated_point[0], y=rotated_point[1])
            )

        logger.info(f"Aligned face by {angle:.2f} degrees")
        return aligned_image, aligned_landmarks

    def generate_svg(
        self, contours: Dict[int, List[LandmarkPoint]], width: int, height: int
    ) -> str:
        """Generate SVG with contour overlays"""
        svg_content = [
            f'<svg width="{width}" height="{height}" xmlns="http://www.w3.org/2000/svg">',
            "<!-- Generated by Facial SVG Service -->",
        ]

        for region_id, points in contours.items():
            if len(points) < 3:
                continue

            style = self.region_styles.get(region_id, self.region_styles[1])
            path_data = self.create_smooth_path(points)

            if path_data:
                svg_content.append(
                    f'<path d="{path_data}" '
                    f'fill="{style["fill"]}" '
                    f'stroke="{style["stroke"]}" '
                    f'stroke-width="2" '
                    f'stroke-dasharray="{style["stroke-dasharray"]}" '
                    f'fill-rule="evenodd"/>'
                )

        svg_content.append("</svg>")
        return "\n".join(svg_content)

    def create_smooth_path(self, points: List[LandmarkPoint]) -> str:
        """Create smooth SVG path from points with better smoothing"""
        if len(points) < 3:
            return ""

        coords = np.array([[p.x, p.y] for p in points])

        # Use cubic bezier curves for smoother paths
        path_commands = [f"M {coords[0][0]:.2f} {coords[0][1]:.2f}"]

        if len(coords) > 2:
            # Simple smoothing: use previous, current, next points for bezier
            for i in range(1, len(coords) - 1):
                # Control points for smoother curves
                x1, y1 = coords[i - 1]
                x2, y2 = coords[i]
                x3, y3 = coords[i + 1]

                # Calculate control points
                cx1 = (x1 + x2) / 2
                cy1 = (y1 + y2) / 2
                cx2 = (x2 + x3) / 2
                cy2 = (y2 + y3) / 2

                path_commands.append(
                    f"C {cx1:.2f} {cy1:.2f} {cx2:.2f} {cy2:.2f} {x2:.2f} {y2:.2f}"
                )

        # Close the path
        path_commands.append("Z")
        return " ".join(path_commands)

    def _create_landmark_based_regions(
        self, landmarks: List[LandmarkPoint]
    ) -> Dict[int, List[LandmarkPoint]]:
        """Create regions based on landmark groupings as fallback"""
        contours = {}

        if len(landmarks) >= 50:
            # These indices need to be adjusted based on your landmark_annotations.jpg
            region_definitions = {
                1: list(range(10, 30)),  # Forehead
                2: list(range(50, 70)),  # Left cheek
                3: list(range(280, 300)),  # Right cheek
                4: list(range(150, 170)),  # Chin
            }

            for region_id, indices in region_definitions.items():
                region_points = []
                for idx in indices:
                    if idx < len(landmarks):
                        region_points.append(landmarks[idx])

                if len(region_points) >= 3:
                    # Add first point at end to close the polygon
                    region_points.append(region_points[0])
                    contours[region_id] = region_points

        return contours

    def debug_segmentation_map(self, segmentation_base64: str):
        """Debug method to understand segmentation map structure"""
        try:
            seg_image = self.base64_to_image(segmentation_base64)
            print(f"Segmentation image shape: {seg_image.shape}")
            print(f"Segmentation image unique values: {np.unique(seg_image)}")

            # If it's a color image, check channels
            if len(seg_image.shape) == 3:
                print(f"Color image - channels: {seg_image.shape[2]}")
                # Check if it's using specific colors for regions
                unique_colors = np.unique(
                    seg_image.reshape(-1, seg_image.shape[2]), axis=0
                )
                print(f"Unique colors (first 10): {unique_colors[:10]}")
            else:
                print(f"Grayscale image - unique values: {np.unique(seg_image)}")

            return True
        except Exception as e:
            print(f"Error debugging segmentation: {e}")
            return False

    def process_segmentation_map(
        self, segmentation_base64: str, landmarks: List[LandmarkPoint]
    ) -> Dict[int, List[LandmarkPoint]]:
        """Process segmentation map to extract region contours"""
        print("=== DEBUG SEGMENTATION PROCESSING ===")

        try:
            seg_image = self.base64_to_image(segmentation_base64)
            print(f"Segmentation image shape: {seg_image.shape}")
            print(f"Segmentation image dtype: {seg_image.dtype}")

            contours = {}

            # Convert to grayscale if it's color
            if len(seg_image.shape) == 3:
                seg_image = cv2.cvtColor(seg_image, cv2.COLOR_BGR2GRAY)
                print("Converted color image to grayscale")

            # Get unique region values (excluding background, usually 0)
            unique_vals = np.unique(seg_image)
            unique_vals = unique_vals[unique_vals > 0]  # Remove background
            print(f"Unique region values: {unique_vals}")

            # Extract contours for each region
            for region_id in unique_vals[:4]:  # Process first 4 regions
                try:
                    # Create binary mask for this region
                    mask = (seg_image == region_id).astype(np.uint8) * 255

                    # Find contours
                    region_contours, _ = cv2.findContours(
                        mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE
                    )

                    if region_contours:
                        # Get the largest contour for this region
                        largest_contour = max(region_contours, key=cv2.contourArea)

                        # Simplify/smooth the contour
                        epsilon = 0.005 * cv2.arcLength(largest_contour, True)
                        smoothed_contour = cv2.approxPolyDP(
                            largest_contour, epsilon, True
                        )

                        # Convert to LandmarkPoints
                        contour_points = []
                        for point in smoothed_contour:
                            x, y = point[0]
                            contour_points.append(LandmarkPoint(x=float(x), y=float(y)))

                        if (
                            len(contour_points) >= 3
                        ):  # Need at least 3 points for a polygon
                            contours[int(region_id)] = contour_points
                            print(f"Region {region_id}: {len(contour_points)} points")

                except Exception as e:
                    print(f"Error processing region {region_id}: {e}")
                    continue

            print(
                f"Successfully extracted {len(contours)} regions from segmentation map"
            )

            # If no contours found from segmentation, fall back to landmark-based regions
            if not contours:
                print("No contours from segmentation, using landmark-based fallback")
                contours = self._create_landmark_based_regions(landmarks)

            return contours

        except Exception as e:
            print(f"Error in segmentation processing: {e}")
            # Fallback to landmark-based regions
            return self._create_landmark_based_regions(landmarks)

    def process_request(self, request_data) -> ProcessResponse:
        """Main processing function"""
        try:
            # Simulate delay only if not in load testing mode
            if not self.load_testing_mode:
                import time

                time.sleep(2)  # Small delay for non-load testing

            original_image = self.base64_to_image(request_data.image)
            landmarks = self._parse_landmarks(request_data.landmarks)

            if len(landmarks) < 10:
                raise ValueError("Insufficient landmarks for face detection")

            aligned_image, aligned_landmarks = self.align_face(
                original_image, landmarks
            )
            contours = self.process_segmentation_map(
                request_data.segmentation_map, aligned_landmarks
            )

            height, width = aligned_image.shape[:2]
            svg_string = self.generate_svg(contours, width, height)
            svg_base64 = base64.b64encode(svg_string.encode("utf-8")).decode("utf-8")

            mask_contours = {}
            for region_id, points in contours.items():
                mask_contours[region_id] = [[p.x, p.y] for p in points]

            return ProcessResponse(svg=svg_base64, mask_contours=mask_contours)

        except Exception as e:
            logger.error(f"Error processing request: {e}")
            raise

    def _parse_landmarks(self, landmarks_data):
        """Handle different landmark data structures"""
        if not landmarks_data:
            return []

        if isinstance(landmarks_data[0], LandmarkPoint):
            return landmarks_data

        if isinstance(landmarks_data[0], dict) and "x" in landmarks_data[0]:
            return [
                LandmarkPoint(x=point["x"], y=point["y"]) for point in landmarks_data
            ]

        if (
            isinstance(landmarks_data[0], list)
            and landmarks_data[0]
            and isinstance(landmarks_data[0][0], dict)
            and "x" in landmarks_data[0][0]
        ):
            flattened = []
            for sublist in landmarks_data:
                for point in sublist:
                    flattened.append(LandmarkPoint(x=point["x"], y=point["y"]))
            return flattened

        logger.warning(f"Unknown landmarks structure: {type(landmarks_data)}")
        return []
